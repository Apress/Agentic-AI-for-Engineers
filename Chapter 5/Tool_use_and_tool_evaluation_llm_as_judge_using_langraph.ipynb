{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "c0129306-7ff9-408d-8602-42c261cbc63f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Environment variables loaded and tracing is set up.\n",
      "AgentState TypedDict defined.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">ðŸš€ Starting agent for query:</span> What were the main announcements from Amazon's latest Invent event?\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1;36mðŸš€ Starting agent for query:\u001b[0m What were the main announcements from Amazon's latest Invent event?\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "================================\u001b[1m Human Message \u001b[0m=================================\n",
      "\n",
      "What were the main announcements from Amazon's latest Invent event?\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">\n",
       "---\n",
       "\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\n",
       "---\n",
       "\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">--- AGENT: Thinking<span style=\"color: #808000; text-decoration-color: #808000\">...</span> ---\n",
       "</pre>\n"
      ],
      "text/plain": [
       "--- AGENT: Thinking\u001b[33m...\u001b[0m ---\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">--- ROUTER: finished ---\n",
       "</pre>\n"
      ],
      "text/plain": [
       "--- ROUTER: finished ---\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "==================================\u001b[1m Ai Message \u001b[0m==================================\n",
      "\n",
      "Amazon's re:Mars 2022, also known as the \"Invent\" event, took place on September 28-30, 2022. The event showcased the company's latest innovations and advancements in areas like robotics, artificial intelligence (AI), computer vision, and more. Here are some of the main announcements from the event:\n",
      "\n",
      "1. **SageMaker Autopilot**: Amazon SageMaker Autopilot is a new service that automates the process of building, training, and deploying machine learning models. It uses reinforcement learning to optimize model performance and reduce costs.\n",
      "2. **Amazon Robotics L6**: The company unveiled its latest robot, the L6, designed for warehouse automation. This robot can navigate complex environments, pick items from shelves, and perform tasks like box packing and labeling.\n",
      "3. **Sumerian 3D Authoring Tool**: Amazon Sumerian is a cloud-based platform that enables users to create interactive, 3D experiences without requiring extensive programming knowledge. The latest version includes new features for creating more complex scenes and interactions.\n",
      "4. **Amazon Rekognition Updates**: Amazon Rekognition, the company's computer vision service, received several updates, including improved object detection, facial recognition, and text analysis capabilities.\n",
      "5. **Alexa Conversations**: Alexa Conversations is a new feature that enables developers to create more natural and conversational voice experiences for users. It allows for more complex dialog flows and better handling of follow-up questions.\n",
      "6. **Amazon Connect Contact Flow Updates**: Amazon Connect, the company's cloud-based contact center solution, received updates to its contact flow features. These include improved routing, queuing, and analytics capabilities.\n",
      "7. **AWS Ground Station**: AWS Ground Station is a new service that enables users to access satellite data directly from their applications. It provides a secure and reliable way to transmit and process large amounts of data.\n",
      "8. **Amazon Chime SDK**: The Amazon Chime SDK is a set of APIs and tools for building video conferencing and collaboration experiences. It includes features like screen sharing, audio/video recording, and more.\n",
      "\n",
      "These announcements demonstrate Amazon's continued investment in AI, robotics, computer vision, and other emerging technologies to drive innovation across various industries.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">\n",
       "---\n",
       "\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\n",
       "---\n",
       "\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #008000; text-decoration-color: #008000; font-weight: bold\">âœ… Done!</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1;32mâœ… Done!\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import os\n",
    "from typing import Annotated, TypedDict\n",
    "from dotenv import load_dotenv\n",
    "\n",
    "# LangChain components\n",
    "from langchain_community.chat_models import ChatOllama\n",
    "from langchain_community.tools.tavily_search import TavilySearchResults\n",
    "from langchain_core.messages import BaseMessage\n",
    "from pydantic import BaseModel, Field\n",
    "\n",
    "# LangGraph components\n",
    "from langgraph.graph import StateGraph\n",
    "from langgraph.graph.message import AnyMessage, add_messages\n",
    "from langgraph.prebuilt import ToolNode\n",
    "\n",
    "# Pretty printing for console output\n",
    "from rich.console import Console\n",
    "\n",
    "# ------------------------------------------------------------\n",
    "# Load environment variables (API keys, configurations, etc.)\n",
    "# ------------------------------------------------------------\n",
    "load_dotenv()\n",
    "console = Console()\n",
    "print(\"Environment variables loaded and tracing is set up.\")\n",
    "\n",
    "from langchain_core.messages import HumanMessage\n",
    "\n",
    "# ------------------------------------------------------------\n",
    "# Agent State Definition\n",
    "# ------------------------------------------------------------\n",
    "class AgentState(TypedDict):\n",
    "    \"\"\"\n",
    "    The state passed through the LangGraph.\n",
    "    - messages: a running list of messages exchanged between user, agent, and tools.\n",
    "    - Annotated[...] with add_messages tells LangGraph to append new messages automatically.\n",
    "    \"\"\"\n",
    "    messages: Annotated[list[AnyMessage], add_messages]\n",
    "\n",
    "print(\"AgentState TypedDict defined.\")\n",
    "\n",
    "# ------------------------------------------------------------\n",
    "# Agent Node - Core LLM Node\n",
    "# ------------------------------------------------------------\n",
    "def agent_node(state: AgentState):\n",
    "    \"\"\"\n",
    "    Main reasoning node.\n",
    "    - Receives all past messages in `state[\"messages\"]`\n",
    "    - Calls the LLM to decide the next action\n",
    "    - Returns the new message so LangGraph can continue routing\n",
    "    - No bind_tools required; ToolNode handles tool execution automatically\n",
    "    \"\"\"\n",
    "    console.print(\"--- AGENT: Thinking... ---\")\n",
    "    resp = llm.invoke(state[\"messages\"])\n",
    "    return {\"messages\": [resp]}\n",
    "\n",
    "# ------------------------------------------------------------\n",
    "# Configure the LLM (Ollama local model)\n",
    "# ------------------------------------------------------------\n",
    "# Ensure you have pulled the model locally:\n",
    "#   ollama pull llama3\n",
    "llm = ChatOllama(\n",
    "    model=\"llama3\",   # can be replaced with \"llama3.1\", \"mistral\", etc.\n",
    "    temperature=0,    # deterministic behavior\n",
    ")\n",
    "\n",
    "# ------------------------------------------------------------\n",
    "# Tool node setup\n",
    "# ------------------------------------------------------------\n",
    "# NOTE: You must define `tools` somewhere above this line.\n",
    "# ToolNode automatically handles calling whichever tool the AI requests.\n",
    "tool_node = ToolNode(tools)\n",
    "\n",
    "# ------------------------------------------------------------\n",
    "# Router Function - Controls graph branching\n",
    "# ------------------------------------------------------------\n",
    "def router_function(state: AgentState) -> str:\n",
    "    \"\"\"\n",
    "    Routing logic for the graph.\n",
    "    - If the last LLM message contains a tool call â†’ route to tool execution\n",
    "    - Otherwise â†’ finish the graph run\n",
    "    \"\"\"\n",
    "    last = state[\"messages\"][-1]\n",
    "\n",
    "    # Detecting tool calls in the LLM output\n",
    "    if getattr(last, \"tool_calls\", None):\n",
    "        console.print(\"--- ROUTER: tool call requested ---\")\n",
    "        return \"call_tool\"\n",
    "\n",
    "    console.print(\"--- ROUTER: finished ---\")\n",
    "    return \"__end__\"\n",
    "\n",
    "# ------------------------------------------------------------\n",
    "# Build the LangGraph\n",
    "# ------------------------------------------------------------\n",
    "graph = StateGraph(AgentState)\n",
    "\n",
    "# Add nodes:\n",
    "graph.add_node(\"agent\", agent_node)   # LLM decision node\n",
    "graph.add_node(\"call_tool\", tool_node)  # Executes tools\n",
    "\n",
    "# Set entry point (first node to run)\n",
    "graph.set_entry_point(\"agent\")\n",
    "\n",
    "# Conditional routing:\n",
    "#   agent â†’ call_tool (if tool call)\n",
    "#   agent â†’ __end__   (if no tool call)\n",
    "graph.add_conditional_edges(\"agent\", router_function)\n",
    "\n",
    "# After a tool is executed, return to agent for next reasoning step\n",
    "graph.add_edge(\"call_tool\", \"agent\")\n",
    "\n",
    "# Compile graph into a runnable app\n",
    "tool_agent_app = graph.compile()\n",
    "\n",
    "# ------------------------------------------------------------\n",
    "# Run the agent with a sample query\n",
    "# ------------------------------------------------------------\n",
    "user_query = \"What were the main announcements from Amazon's latest Invent event?\"\n",
    "\n",
    "# Initial state for LangGraph\n",
    "initial_input = {\"messages\": [HumanMessage(content=user_query)]}\n",
    "\n",
    "console.print(f\"[bold cyan]ðŸš€ Starting agent for query:[/bold cyan] {user_query}\")\n",
    "\n",
    "# Stream results as they come in (token/step streaming)\n",
    "for chunk in tool_agent_app.stream(initial_input, stream_mode=\"values\"):\n",
    "    # Pretty print each incremental output message\n",
    "    chunk[\"messages\"][-1].pretty_print()\n",
    "    console.print(\"\\n---\\n\")\n",
    "\n",
    "console.print(\"[bold green]âœ… Done![/bold green]\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "05513112-ea33-4864-9db5-3c63bb95930b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">--- AGENT: Thinking<span style=\"color: #808000; text-decoration-color: #808000\">...</span> ---\n",
       "</pre>\n"
      ],
      "text/plain": [
       "--- AGENT: Thinking\u001b[33m...\u001b[0m ---\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">--- ROUTER: finished ---\n",
       "</pre>\n"
      ],
      "text/plain": [
       "--- ROUTER: finished ---\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">\n",
       "<span style=\"color: #800080; text-decoration-color: #800080; font-weight: bold\">--- Evaluation ---</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\n",
       "\u001b[1;35m--- Evaluation ---\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">{</span>\n",
       "    <span style=\"color: #008000; text-decoration-color: #008000\">'tool_selection_score'</span>: <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">5</span>,\n",
       "    <span style=\"color: #008000; text-decoration-color: #008000\">'tool_input_score'</span>: <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">4</span>,\n",
       "    <span style=\"color: #008000; text-decoration-color: #008000\">'synthesis_quality_score'</span>: <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">5</span>,\n",
       "    <span style=\"color: #008000; text-decoration-color: #008000\">'justification'</span>: <span style=\"color: #008000; text-decoration-color: #008000\">\"The AI agent effectively selected relevant tools and provided accurate information about </span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">Amazon's Invent event, with minor issues in tool input. The synthesis quality is excellent, providing a clear </span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">summary of the main announcements.\"</span>\n",
       "<span style=\"font-weight: bold\">}</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m{\u001b[0m\n",
       "    \u001b[32m'tool_selection_score'\u001b[0m: \u001b[1;36m5\u001b[0m,\n",
       "    \u001b[32m'tool_input_score'\u001b[0m: \u001b[1;36m4\u001b[0m,\n",
       "    \u001b[32m'synthesis_quality_score'\u001b[0m: \u001b[1;36m5\u001b[0m,\n",
       "    \u001b[32m'justification'\u001b[0m: \u001b[32m\"The AI agent effectively selected relevant tools and provided accurate information about \u001b[0m\n",
       "\u001b[32mAmazon's Invent event, with minor issues in tool input. The synthesis quality is excellent, providing a clear \u001b[0m\n",
       "\u001b[32msummary of the main announcements.\"\u001b[0m\n",
       "\u001b[1m}\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import json\n",
    "import re\n",
    "\n",
    "def build_conversation_trace(messages):\n",
    "    trace_lines = []\n",
    "    for m in messages:\n",
    "        role = getattr(m, \"type\", \"unknown\")\n",
    "        content = getattr(m, \"content\", \"\")\n",
    "        tool_calls = getattr(m, \"tool_calls\", \"\")\n",
    "        trace_lines.append(f\"{role.upper()}:\\n{content}\\n{tool_calls}\\n\")\n",
    "    return \"\\n\".join(trace_lines)\n",
    "\n",
    "\n",
    "def build_eval_prompt(conversation_trace: str):\n",
    "    return f\"\"\"\n",
    "You are a rigorous evaluator of AI agent behaviors and tool use.\n",
    "\n",
    "Evaluate the agent's behavior based ONLY on the conversation trace below.\n",
    "\n",
    "Return a JSON object with the following keys:\n",
    "\n",
    "- tool_selection_score: integer from 1â€“5  \n",
    "- tool_input_score: integer from 1â€“5  \n",
    "- synthesis_quality_score: integer from 1â€“5  \n",
    "- overall_score: integer from 1â€“5  \n",
    "- justification: a concise explanation (string)\n",
    "\n",
    "CRITICAL RULES:\n",
    "- Output valid JSON ONLY\n",
    "- Do not add comments, markdown, code fences, or explanations\n",
    "- All values must match the required types\n",
    "\n",
    "Conversation Trace:\n",
    "--------------------\n",
    "{conversation_trace}\n",
    "--------------------\n",
    "\n",
    "Return ONLY the JSON.\n",
    "\"\"\"\n",
    "\n",
    " \n",
    "\n",
    "def evaluate_run(final_state, llm, console=None):\n",
    "    # Build trace\n",
    "    conversation_trace = build_conversation_trace(final_state[\"messages\"])\n",
    "    \n",
    "    # Build prompt\n",
    "    eval_prompt = build_eval_prompt(conversation_trace)\n",
    "\n",
    "    # Call evaluator LLM\n",
    "    response = llm.invoke(eval_prompt)\n",
    "    raw = response.content\n",
    "\n",
    "    try:\n",
    "        parsed = json.loads(raw)\n",
    "    except:\n",
    "        parsed = repair_json(raw)\n",
    "\n",
    "    evaluation = ToolUseEvaluation(**parsed)\n",
    "\n",
    "    if console:\n",
    "        console.print(\"\\n[bold magenta]--- Evaluation ---[/bold magenta]\")\n",
    "        console.print(evaluation.model_dump())\n",
    "\n",
    "    return evaluation\n",
    "final_state = tool_agent_app.invoke(initial_input)\n",
    "(final_state['messages'][-1].pretty_print())\n",
    "evaluation = evaluate_run(final_state, llm, console)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "13b3d7b6-ef51-40dc-a15a-e809ef8d5bc5",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
