{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "3ecfcb8c-4711-4346-970d-e782e6534ce6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚úÖ OpenAI Client Initialized successfully.\n",
      "üî≠ OpenTelemetry Tracing Details üî≠\n",
      "|  Phoenix Project: employee-analysis-agent\n",
      "|  Span Processor: SimpleSpanProcessor\n",
      "|  Collector Endpoint: http://localhost:6006/v1/traces\n",
      "|  Transport: HTTP + protobuf\n",
      "|  Transport Headers: {}\n",
      "|  \n",
      "|  Using a default SpanProcessor. `add_span_processor` will overwrite this default.\n",
      "|  \n",
      "|  ‚ö†Ô∏è WARNING: It is strongly advised to use a BatchSpanProcessor in production environments.\n",
      "|  \n",
      "|  `register` has set this TracerProvider as the global OpenTelemetry default.\n",
      "|  To disable this behavior, call `register` with `set_global_tracer_provider=False`.\n",
      "\n",
      "\n",
      "ü§ñ Agent starting with query: First, get the performance scores and salaries for the Engineering department. Then, analyze the data to tell me if higher pay correlates with better performance. Finally, create a visualization code to prove your point.\n",
      "üõ†Ô∏è Agent is calling tool: lookup_employee_data\n",
      "üõ†Ô∏è Agent is calling tool: analyze_data\n",
      "üõ†Ô∏è Agent is calling tool: generate_visualization\n",
      "\n",
      "‚úÖ Agent finished.\n",
      "\n",
      "------------------------------------------------\n",
      "FINAL RESPONSE:\n",
      "### Analysis Results\n",
      "\n",
      "Based on the provided data from the Engineering department, we found a strong positive correlation between salary and performance score. The correlation coefficient calculated is approximately **0.95**, indicating that higher pay is associated with better performance.\n",
      "\n",
      "### Visualization Code\n",
      "\n",
      "Here is the Python code to create a scatter plot visualizing the correlation between salary and performance score:\n",
      "\n",
      "```python\n",
      "import pandas as pd\n",
      "import matplotlib.pyplot as plt\n",
      "import seaborn as sns\n",
      "\n",
      "data = {\n",
      "    'performance_score': [4.5, 4.8, 3.5, 4.9],\n",
      "    'salary': [120000, 135000, 110000, 140000]\n",
      "}\n",
      "\n",
      "df = pd.DataFrame(data)\n",
      "\n",
      "plt.figure(figsize=(10, 6))\n",
      "sns.scatterplot(data=df, x='salary', y='performance_score')\n",
      "plt.title('Correlation between Salary and Performance Score in Engineering Department')\n",
      "plt.xlabel('Salary')\n",
      "plt.ylabel('Performance Score')\n",
      "plt.grid(True)\n",
      "plt.show()\n",
      "```\n",
      "\n",
      "This visualization will help illustrate the relationship between salary and performance scores among employees in the Engineering department.\n",
      "------------------------------------------------\n",
      "View traces at: http://localhost:6006\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import json\n",
    "import pandas as pd\n",
    "import duckdb\n",
    "from pydantic import BaseModel, Field\n",
    "from openai import OpenAI\n",
    "from dotenv import load_dotenv\n",
    "\n",
    "# Observability and Tracing imports (Phoenix)\n",
    "import phoenix as px\n",
    "from openinference.instrumentation.openai import OpenAIInstrumentor\n",
    "from openinference.instrumentation import TracerProvider\n",
    "from phoenix.otel import register\n",
    "from opentelemetry.trace import StatusCode\n",
    "import nest_asyncio\n",
    "\n",
    "# Load .env variables immediately\n",
    "load_dotenv()\n",
    "\n",
    "# Apply asyncio patch\n",
    "nest_asyncio.apply()\n",
    "\n",
    "# ==============================================================================\n",
    "# 1. CONFIGURATION & SETUP\n",
    "# ==============================================================================\n",
    "\n",
    "MODEL = \"gpt-4o-mini\"\n",
    "# üîÑ CHANGE 1: New file name\n",
    "TRANSACTION_DATA_FILE_PATH = 'employee_data.parquet'\n",
    "\n",
    "\n",
    "# API Key Handling\n",
    "api_key = os.getenv(\"OPENAI_API_KEY\")\n",
    "if not api_key:\n",
    "    raise ValueError(\"‚ùå API Key missing! Please set 'OPENAI_API_KEY' in your .env file.\")\n",
    "\n",
    "client = OpenAI(api_key=api_key)\n",
    "print(\"‚úÖ OpenAI Client Initialized successfully.\")\n",
    "\n",
    "# ==============================================================================\n",
    "# 2. PHOENIX TRACING SETUP\n",
    "# ==============================================================================\n",
    "PROJECT_NAME = \"employee-analysis-agent\"\n",
    "os.environ[\"PHOENIX_PROJECT_NAME\"] = PROJECT_NAME\n",
    "\n",
    "# Ensure Phoenix server is running on port 6006\n",
    "tracer_provider = register(\n",
    "    project_name=os.environ[\"PHOENIX_PROJECT_NAME\"], # Best practice to reference the env var\n",
    "    endpoint=\"http://localhost:6006/v1/traces\"\n",
    ")\n",
    "\n",
    "OpenAIInstrumentor().instrument(tracer_provider=tracer_provider)\n",
    "tracer = tracer_provider.get_tracer(__name__)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "# ==============================================================================\n",
    "# 3. TOOL DEFINITIONS\n",
    "# ==============================================================================\n",
    "\n",
    "# --- TOOL 1: Database Lookup (Text-to-SQL) ---\n",
    "SQL_GENERATION_PROMPT = \"\"\"\n",
    "Generate an SQL query based on a prompt. Do not reply with anything besides the SQL query.\n",
    "The prompt is: {prompt}\n",
    "\n",
    "The available columns are: {columns}\n",
    "The table name is: {table_name}\n",
    "\"\"\"\n",
    "\n",
    "def generate_sql_query(prompt: str, columns: list, table_name: str) -> str:\n",
    "    formatted_prompt = SQL_GENERATION_PROMPT.format(prompt=prompt, columns=columns, table_name=table_name)\n",
    "    response = client.chat.completions.create(\n",
    "        model=MODEL,\n",
    "        messages=[{\"role\": \"user\", \"content\": formatted_prompt}],\n",
    "    )\n",
    "    return response.choices[0].message.content\n",
    "\n",
    "# üîÑ CHANGE 2: Renamed function and updated table logic\n",
    "@tracer.tool() \n",
    "def lookup_employee_data(prompt: str) -> str:\n",
    "    \"\"\"\n",
    "    Tool Logic:\n",
    "    1. Reads employee parquet file.\n",
    "    2. SQL Generation via DuckDB.\n",
    "    \"\"\"\n",
    "    try:\n",
    "        # üîÑ CHANGE 3: Table name is now 'employees'\n",
    "        table_name = \"employees\"\n",
    "        \n",
    "        # Load data\n",
    "        df = pd.read_parquet(TRANSACTION_DATA_FILE_PATH)\n",
    "        \n",
    "        # Register the dataframe as a SQL table in DuckDB\n",
    "        duckdb.sql(f\"CREATE OR REPLACE TABLE {table_name} AS SELECT * FROM df\")\n",
    "\n",
    "        # Step 2: Generate SQL\n",
    "        sql_query = generate_sql_query(prompt, list(df.columns), table_name)\n",
    "        \n",
    "        # Cleaning: Remove markdown code blocks\n",
    "        sql_query = sql_query.strip().replace(\"```sql\", \"\").replace(\"```\", \"\")\n",
    "        \n",
    "        # Step 3: Execute SQL with tracing\n",
    "        with tracer.start_as_current_span(\"execute_sql_query\") as span:\n",
    "            result = duckdb.sql(sql_query).df()\n",
    "            span.set_attribute(\"sql_query\", sql_query)\n",
    "            span.set_status(StatusCode.OK)\n",
    "        \n",
    "        return result.to_string()\n",
    "        \n",
    "    except Exception as e:\n",
    "        return f\"Error accessing data: {str(e)}\"\n",
    "\n",
    "\n",
    "# --- TOOL 2: Data Analysis ---\n",
    "DATA_ANALYSIS_PROMPT = \"\"\"\n",
    "Analyze the following data: {data}\n",
    "Your job is to answer the following question: {prompt}\n",
    "\"\"\"\n",
    "\n",
    "@tracer.tool()\n",
    "def analyze_data(prompt: str, data: str) -> str:\n",
    "    \"\"\"Derive insights from raw data.\"\"\"\n",
    "    formatted_prompt = DATA_ANALYSIS_PROMPT.format(data=data, prompt=prompt)\n",
    "\n",
    "    response = client.chat.completions.create(\n",
    "        model=MODEL,\n",
    "        messages=[{\"role\": \"user\", \"content\": formatted_prompt}],\n",
    "    )\n",
    "    \n",
    "    analysis = response.choices[0].message.content\n",
    "    return analysis if analysis else \"No analysis could be generated\"\n",
    "\n",
    "\n",
    "# --- TOOL 3: Data Visualization ---\n",
    "class VisualizationConfig(BaseModel):\n",
    "    chart_type: str = Field(..., description=\"Type of chart (bar, line, scatter)\")\n",
    "    x_axis: str = Field(..., description=\"Column name for x-axis\")\n",
    "    y_axis: str = Field(..., description=\"Column name for y-axis\")\n",
    "    title: str = Field(..., description=\"Chart title\")\n",
    "\n",
    "@tracer.chain()\n",
    "def extract_chart_config(data: str, visualization_goal: str) -> dict:\n",
    "    prompt = f\"Generate chart config for this data based on goal: {visualization_goal}\\nData: {data}\"\n",
    "    \n",
    "    response = client.beta.chat.completions.parse(\n",
    "        model=MODEL,\n",
    "        messages=[{\"role\": \"user\", \"content\": prompt}],\n",
    "        response_format=VisualizationConfig,\n",
    "    )\n",
    "    \n",
    "    content = response.choices[0].message.parsed\n",
    "    return {\n",
    "        \"chart_type\": content.chart_type,\n",
    "        \"x_axis\": content.x_axis,\n",
    "        \"y_axis\": content.y_axis,\n",
    "        \"title\": content.title,\n",
    "        \"data_snippet\": data[:100] \n",
    "    }\n",
    "\n",
    "CREATE_CHART_PROMPT = \"\"\"\n",
    "Write python code (using matplotlib/seaborn) to create a chart based on this config.\n",
    "Only return the code, no markdown.\n",
    "config: {config}\n",
    "\"\"\"\n",
    "\n",
    "@tracer.chain()\n",
    "def create_chart_code(config: dict) -> str:\n",
    "    formatted_prompt = CREATE_CHART_PROMPT.format(config=config)\n",
    "    response = client.chat.completions.create(\n",
    "        model=MODEL,\n",
    "        messages=[{\"role\": \"user\", \"content\": formatted_prompt}],\n",
    "    )\n",
    "    code = response.choices[0].message.content\n",
    "    return code.strip().replace(\"```python\", \"\").replace(\"```\", \"\")\n",
    "\n",
    "@tracer.tool()\n",
    "def generate_visualization(data: str, visualization_goal: str) -> str:\n",
    "    config = extract_chart_config(data, visualization_goal)\n",
    "    code = create_chart_code(config)\n",
    "    return f\"Generated Python Code for Chart:\\n{code}\"\n",
    "\n",
    "\n",
    "# ==============================================================================\n",
    "# 4. TOOL SCHEMA & MAPPING\n",
    "# ==============================================================================\n",
    "tool_implementations = {\n",
    "    \"lookup_employee_data\": lookup_employee_data,\n",
    "    \"analyze_data\": analyze_data,\n",
    "    \"generate_visualization\": generate_visualization\n",
    "}\n",
    "\n",
    "# üîÑ CHANGE 4: Updated Schema descriptions\n",
    "tools_schema = [\n",
    "    {\n",
    "        \"type\": \"function\",\n",
    "        \"function\": {\n",
    "            \"name\": \"lookup_employee_data\",\n",
    "            \"description\": \"Query the Employee SQL database for info on salaries, departments, and performance.\",\n",
    "            \"parameters\": {\n",
    "                \"type\": \"object\",\n",
    "                \"properties\": {\n",
    "                    \"prompt\": {\"type\": \"string\", \"description\": \"The question to ask the database (e.g. 'average salary by dept')\"}\n",
    "                },\n",
    "                \"required\": [\"prompt\"]\n",
    "            }\n",
    "        }\n",
    "    },\n",
    "    {\n",
    "        \"type\": \"function\",\n",
    "        \"function\": {\n",
    "            \"name\": \"analyze_data\",\n",
    "            \"description\": \"Analyze text or tabular data to find trends.\",\n",
    "            \"parameters\": {\n",
    "                \"type\": \"object\",\n",
    "                \"properties\": {\n",
    "                    \"data\": {\"type\": \"string\", \"description\": \"The data found from lookup_employee_data\"},\n",
    "                    \"prompt\": {\"type\": \"string\", \"description\": \"Specific question about the data\"}\n",
    "                },\n",
    "                \"required\": [\"data\", \"prompt\"]\n",
    "            }\n",
    "        }\n",
    "    },\n",
    "    {\n",
    "        \"type\": \"function\",\n",
    "        \"function\": {\n",
    "            \"name\": \"generate_visualization\",\n",
    "            \"description\": \"Generate Python code to plot data.\",\n",
    "            \"parameters\": {\n",
    "                \"type\": \"object\",\n",
    "                \"properties\": {\n",
    "                    \"data\": {\"type\": \"string\", \"description\": \"The data to plot\"},\n",
    "                    \"visualization_goal\": {\"type\": \"string\", \"description\": \"What the chart should show\"}\n",
    "                },\n",
    "                \"required\": [\"data\", \"visualization_goal\"]\n",
    "            }\n",
    "        }\n",
    "    }\n",
    "]\n",
    "\n",
    "\n",
    "# ==============================================================================\n",
    "# 5. AGENT ORCHESTRATION LOOP\n",
    "# ==============================================================================\n",
    "\n",
    "@tracer.chain()\n",
    "def handle_tool_calls(tool_calls, messages):\n",
    "    for tool_call in tool_calls:\n",
    "        fn_name = tool_call.function.name\n",
    "        fn_args = json.loads(tool_call.function.arguments)\n",
    "        \n",
    "        print(f\"üõ†Ô∏è Agent is calling tool: {fn_name}\")\n",
    "        \n",
    "        function_to_call = tool_implementations.get(fn_name)\n",
    "        \n",
    "        if function_to_call:\n",
    "            result = function_to_call(**fn_args)\n",
    "            messages.append({\n",
    "                \"role\": \"tool\", \n",
    "                \"content\": str(result), \n",
    "                \"tool_call_id\": tool_call.id\n",
    "            })\n",
    "        else:\n",
    "            print(f\"Error: Tool {fn_name} not found.\")\n",
    "            \n",
    "    return messages\n",
    "\n",
    "def run_agent(user_query: str):\n",
    "    print(f\"\\nü§ñ Agent starting with query: {user_query}\")\n",
    "    \n",
    "    messages = [\n",
    "        {\"role\": \"system\", \"content\": \"You are a helpful HR data analyst agent. Use the available tools to answer questions.\"},\n",
    "        {\"role\": \"user\", \"content\": user_query}\n",
    "    ]\n",
    "\n",
    "    while True:\n",
    "        response = client.chat.completions.create(\n",
    "            model=MODEL,\n",
    "            messages=messages,\n",
    "            tools=tools_schema,\n",
    "        )\n",
    "\n",
    "        ai_message = response.choices[0].message\n",
    "        messages.append(ai_message.model_dump())\n",
    "\n",
    "        if ai_message.tool_calls:\n",
    "            messages = handle_tool_calls(ai_message.tool_calls, messages)\n",
    "        else:\n",
    "            print(\"\\n‚úÖ Agent finished.\")\n",
    "            return ai_message.content\n",
    "\n",
    "\n",
    "# ==============================================================================\n",
    "# 6. MAIN EXECUTION\n",
    "# ==============================================================================\n",
    "def create_dummy_data():\n",
    "    \"\"\"Generates a dummy parquet file for HR/Employee data.\"\"\"\n",
    "    if not os.path.exists(TRANSACTION_DATA_FILE_PATH):\n",
    "        print(\"Creating dummy employee data...\")\n",
    "        # üîÑ CHANGE 5: New Data Structure\n",
    "        data = {\n",
    "            'employee_id': [101, 102, 103, 104, 105, 106, 107, 108],\n",
    "            'name': ['Alice', 'Bob', 'Charlie', 'Diana', 'Evan', 'Fiona', 'George', 'Hannah'],\n",
    "            'department': ['Engineering', 'Sales', 'Engineering', 'HR', 'Sales', 'Engineering', 'Marketing', 'Engineering'],\n",
    "            'salary': [120000, 85000, 135000, 70000, 95000, 110000, 88000, 140000],\n",
    "            'years_experience': [5, 3, 8, 2, 5, 4, 3, 10],\n",
    "            'performance_score': [4.5, 4.0, 4.8, 3.9, 4.2, 3.5, 4.1, 4.9]\n",
    "        }\n",
    "        df = pd.DataFrame(data)\n",
    "        df.to_parquet(TRANSACTION_DATA_FILE_PATH)\n",
    "        print(f\"Saved to {TRANSACTION_DATA_FILE_PATH}\")\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    create_dummy_data()\n",
    "    \n",
    "    # üîÑ UPDATED QUERY: Forces the agent to \"Analyze\" first\n",
    "    QUERY = (\n",
    "        \"First, get the performance scores and salaries for the Engineering department. \"\n",
    "        \"Then, analyze the data to tell me if higher pay correlates with better performance. \"\n",
    "        \"Finally, create a visualization code to prove your point.\"\n",
    "    )\n",
    "    \n",
    "    final_response = run_agent(QUERY)\n",
    "    print(\"\\n------------------------------------------------\")\n",
    "    print(\"FINAL RESPONSE:\")\n",
    "    print(final_response)\n",
    "    print(\"------------------------------------------------\")\n",
    "    print(f\"View traces at: http://localhost:6006\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eefeda6c-c056-4324-ac0d-520244173e4a",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
